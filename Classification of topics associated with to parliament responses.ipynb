{"cells":[{"cell_type":"code","execution_count":2,"id":"c8e03a55","metadata":{"id":"c8e03a55","executionInfo":{"status":"ok","timestamp":1686510556909,"user_tz":-120,"elapsed":817,"user":{"displayName":"Chama Kasonde","userId":"00636772021906929690"}}},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"05590653","metadata":{"id":"05590653","outputId":"eeceaa62-2e96-424e-92f0-6cd5a44c96ca"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\jonas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\jonas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\jonas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# Download NLTK resources\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","\n","# Preprocess the text\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","def preprocess_text(text):\n","    tokens = nltk.word_tokenize(text.lower())  # Tokenization\n","    tokens = [token for token in tokens if token.isalpha()]  # Remove non-alphabetic characters\n","    tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords\n","    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatization\n","    return ' '.join(tokens)\n","\n","# Apply text preprocessing to 'content' column\n","df['preprocessed_text'] = df['content'].apply(preprocess_text)\n","\n","# Create TF-IDF features\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(df['preprocessed_text'])"]},{"cell_type":"markdown","id":"244f8077","metadata":{"id":"244f8077"},"source":["# 3 Define the target labels:\n","Decide on the set of target labels or topics that you want to predict. You'll need to have labeled examples for each topic in your dataset."]},{"cell_type":"code","execution_count":null,"id":"17e61c0e","metadata":{"id":"17e61c0e"},"outputs":[],"source":["# Assuming you have a list of topic labels corresponding to each row in the DataFrame\n","y = ['Legislation and Policy', 'Governance and Administration', 'Justice and Legal Affairs', 'Public Health', 'Education and Research', 'Social Issues', 'Economy and Finance: ', 'Justice and Legal Affairs', 'Public Health'\n","     , 'Education and Research', 'Infrastructure and Development', 'Foreign Affairs and Diplomacy', 'Public Health', 'Governance and Administration', 'Social Issues', 'Infrastructure and Development', 'Justice and Legal Affairs'\n","     , 'Legislation and Policy', 'Education and Research:', 'Education and Research:', 'Economy and Finance: ', 'Legislation and Policy', 'Security and Defense', 'Public Health', 'Social Issues',\n","     'Infrastructure and Development','Economy and Finance: ', 'Justice and Legal Affairs', 'Security and Defense', 'Economy and Finance: ', 'Governance and Administration', 'Infrastructure and Development', 'Education and Research', 'Infrastructure and Development'\n","     , 'Economy and Finance: ', 'Social Issues', 'Legislation and Policy', 'Public Health', 'Infrastructure and Development', 'Governance and Administration', 'Public Health', 'Foreign Affairs and Diplomacy'\n","     , 'Governance and Administration', 'Infrastructure and Development', 'Economy and Finance', 'Social Issues', 'Education and Research:', 'Justice and Legal Affairs', 'Economy and Finance', 'Legislation and Policy'\n","    ,'Economy and Finance: ', 'Foreign Affairs and Diplomacy', 'Security and Defense', 'Governance and Administration', 'Legislation and Policy', 'Social Issues', 'Security and Defense', 'Governance and Administration', 'Security and Defense'\n","     , 'Legislation and Policy', 'Legislation and Policy', 'Justice and Legal Affairs', 'Security and Defense', 'Education and Research', 'Governance and Administration', 'Public Health', 'Justice and Legal Affairs'\n","     , 'Public Health', 'Public Health', 'Education and Research', 'Governance and Administration', 'Legislation and Policy', 'Justice and Legal Affairs', 'Legislation and Policy', 'Social Issues'\n","    ,'Education and Research', 'Infrastructure and Development', 'Governance and Administration', 'Justice and Legal Affairs', 'Public Health', 'Public Health', 'Economy and Finance: ', 'Security and Defense', 'Public Health'\n","     , 'Economy and Finance: ', 'Economy and Finance: ', 'Social Issues', 'Governance and Administration', 'Public Health', 'Justice and Legal Affairs', 'Social Issues', 'Social Issues'\n","     , 'Social Issues', 'Legislation and Policy', 'Foreign Affairs and Diplomacy', 'Economy and Finance: ', 'Public Health', 'Foreign Affairs and Diplomacy', 'Security and Defense', 'Justice and Legal Affairs'\n","    , 'Public Health','Education and Research:', 'Education and Research:', 'Economy and Finance: ', 'Governance and Administration', 'Foreign Affairs and Diplomacy', 'Legislation and Policy'] \n","# Add your topic labels here"]},{"cell_type":"code","execution_count":null,"id":"49ca58e8","metadata":{"id":"49ca58e8"},"outputs":[],"source":["# Convert the preprocessed_text column to a new DataFrame\n","preprocessed_df = pd.DataFrame({'preprocessed_text': df['preprocessed_text']})\n","\n","# Save the preprocessed DataFrame to an Excel file\n","preprocessed_df.to_excel('preprocessed_data.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"78e45817","metadata":{"id":"78e45817","outputId":"67cdf8e5-eb6c-4f83-ec57-0744dd0450e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['content', 'preprocessed_text'], dtype='object')\n"]}],"source":["# Check the columns of the DataFrame\n","print(df.columns)\n"]},{"cell_type":"code","execution_count":null,"id":"b361929a","metadata":{"id":"b361929a","outputId":"37260d5d-4d86-4c82-9560-2ecd8756202b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of columns: 2\n","Number of rows: 107\n"]}],"source":["# Find the number of columns and rows in the DataFrame\n","num_rows, num_columns = df.shape\n","print(\"Number of columns:\", num_columns)\n","print(\"Number of rows:\", num_rows)\n"]},{"cell_type":"code","execution_count":null,"id":"ba860ec2","metadata":{"id":"ba860ec2"},"outputs":[],"source":["# Drop the \"content\" column from the DataFrame\n","df = df.drop(\"content\", axis=1)"]},{"cell_type":"code","execution_count":null,"id":"7e65a5cc","metadata":{"id":"7e65a5cc","outputId":"dce3ed9d-b8d6-4d70-d95e-3527fa6a55cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of columns: 1\n","Number of rows: 107\n"]}],"source":["# Find the number of columns and rows in the DataFrame\n","num_rows, num_columns = df.shape\n","print(\"Number of columns:\", num_columns)\n","print(\"Number of rows:\", num_rows)\n"]},{"cell_type":"markdown","id":"909ed000","metadata":{"id":"909ed000"},"source":["# 4 Split the data into training and testing sets:"]},{"cell_type":"code","execution_count":null,"id":"4801245f","metadata":{"id":"4801245f"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","id":"6a96fa3e","metadata":{"id":"6a96fa3e"},"source":["# 5 Train a text classification model:\n","There are several algorithms you can use for text classification, such as Naive Bayes, Support Vector Machines (SVM),"]},{"cell_type":"code","execution_count":null,"id":"41fb62e3","metadata":{"id":"41fb62e3","outputId":"6fd52525-5a18-4c04-ca8f-22064f190ecf"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"],"text/plain":["MultinomialNB()"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.naive_bayes import MultinomialNB\n","\n","# Train the classifier\n","clf = MultinomialNB()\n","clf.fit(X_train, y_train)\n"]},{"cell_type":"markdown","id":"cc324df5","metadata":{"id":"cc324df5"},"source":["# 6 Evaluate the model:"]},{"cell_type":"code","execution_count":null,"id":"fbc6dc69","metadata":{"id":"fbc6dc69","outputId":"c5179169-93c5-4c4c-d420-aae532b30e57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.045454545454545456\n"]}],"source":["# Evaluate the model\n","accuracy = clf.score(X_test, y_test)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"markdown","id":"6a0cecec","metadata":{"id":"6a0cecec"},"source":["# 7 Use the trained model to predict topics:\n","You can use the trained model to predict topics for new, unseen text:"]},{"cell_type":"code","execution_count":null,"id":"14246841","metadata":{"id":"14246841","outputId":"613f9425-6c68-44a3-9a33-3d2654aa616f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Topic: ['Public Health']\n"]}],"source":["new_text = \"building houses\"\n","preprocessed_text = preprocess_text(new_text)\n","X_new = vectorizer.transform([preprocessed_text])\n","predicted_topic = clf.predict(X_new)\n","print(\"Predicted Topic:\", predicted_topic)\n"]},{"cell_type":"markdown","id":"5d0ca3d5","metadata":{"id":"5d0ca3d5"},"source":["Note: This is a basic outline of the text classification process, and you can experiment with different models, feature representations, or preprocessing techniques based on your specific requirements and dataset.\n","\n","Remember to have a labeled dataset with examples for each topic to train and evaluate your model effectively."]},{"cell_type":"code","execution_count":null,"id":"043118bf","metadata":{"id":"043118bf"},"outputs":[],"source":["# Load the Excel data\n","df = pd.read_excel(\"preprocessed_data.xlsx\")\n","\n","# Create a new column 'topic' and assign the list of labels\n","df['topic'] = y\n","\n","# Save the DataFrame with the added 'topic' column to a new Excel file\n","df.to_excel(\"updated_data.xlsx\", index=False)\n"]},{"cell_type":"code","execution_count":null,"id":"5f43f8be","metadata":{"id":"5f43f8be"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}